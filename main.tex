\documentclass[12pt,toc=bibnumbered, a4paper,twoside,DIV=11,BCOR=.5cm]{scrbook}
%\documentclass[12pt,toc=bibnumbered, a4paper,twoside,DIV=calc]{scrbook}
%\documentclass[12pt,toc=bibnumbered, a4paper,twoside]{book}

\usepackage{hyperref}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{calc}
\usepackage{refstyle}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{multicol}
%\usepackage{pslatex}
\usepackage{microtype}
\usepackage{natbib}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{tabu}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{mdwlist}
\usepackage{url}
\usepackage[noend]{algpseudocode}
\usepackage[small]{caption}
\usepackage{setspace}
\usepackage{color}
\usepackage{minted}
\usepackage[german,english]{babel}
%\renewcommand*\sfdefault{avant}
 %\usepackage{helvet}
\usepackage[defaultsans]{droidsans}
%\renewcommand*\sfdefault{lmssq}

\usepackage{garamondx}
%\usepackage[urw-garamond]{mathdesign}
\usepackage{xspace}
\onehalfspacing
\KOMAoptions{DIV=last}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}

\newcommand{\x}{\checkmark}
\renewcommand{\o}{$\times$}

\makeatletter
\let\OldStatex\Statex
\renewcommand{\Statex}[1][3]{%
\setlength\@tempdima{\algorithmicindent}%
\OldStatex\hskip\dimexpr#1\@tempdima\relax}
\makeatother

\definecolor{rulecolor}{rgb}{0.80,0.80,0.80}
\newminted{python}{frame=single,rulecolor=\color{rulecolor}, linenos, xleftmargin=7mm}

\newcommand{\pystruct}{\textsc{PyStruct}\xspace}
\newcommand{\svmstruct}{SVM$^\text{struct}$\xspace}

\algrenewcommand{\algorithmicrequire}{\textbf{Input:}}
\algrenewcommand{\algorithmicensure}{\textbf{Output:}}

\newcolumntype{R}{>{\raggedleft\arraybackslash}X}
\newcolumntype{C}{>{\centered\arraybackslash}X}

\newcommand{\fix}{\marginpar{FIX}} \newcommand{\new}{\marginpar{NEW}}
\newcommand\etal{~et\,al.~}

\newcommand\hzero{\ensuremath{p(h_I(x)=0)}}
\newcommand\bagerror{\ensuremath{p(h_B(X) \neq Y)}}
\newcommand\instanceerror{\ensuremath{p(h_I(x) \neq y)}}

%\newcommand{\hoch}[1]{^{(#1)}}
\newcommand{\hoch}[1]{^{#1}}

\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\newcommand{\W}{\mathcal{W}}


\newcommand{\given}{\, | \,}
\newcommand{\B}[1]{\textbf{#1}}

\setlength{\tabcolsep}{2pt}

\begin{document}

\begin{spacing}{1.6}
\begin{titlepage}

\begin{center}
\Large\sffamily
\vspace*{1cm}
\textbf{{\huge Learning Structured Prediction for Semantic Image Segmentation}}\\[5mm]
Dissertation\\
zur\\
Erlangung des Doktorgrades (Dr.\ rer.\ nat.)\\
der\\
Mathematisch-Naturwissenschaftlichen Fakult\"at\\
der\\
Rheinischen Friedrich-Wilhelm Universit\"at Bonn\\
vorgelegt von\\
{\LARGE Andreas Christian M\"uller}\\
aus\\
Offenbach am Main\\
Bonn, September 2013
\end{center}
\end{titlepage}
%
%\thispagestyle{empty}
\clearpage
\pagenumbering{Roman}
\setcounter{page}{2}
\vspace*{5cm}
\Large\sffamily
\begin{center}
Angefertigt mit Genehmigung\\
der Mathematisch-Naturwissenschaftlichen Fakult\"at\\
der Rheinischen Friedrich-Wilhelms-Universit\"at Bonn\\
\end{center}
1. Gutachter Prof. Dr. Sven Behnke\\
2. Gutachter Prof. Dr. Reinhard Klein\\
Tag der Promotion:\\
Erscheinungsjahr: 2013\\
\end{spacing}
\tableofcontents
%\listoffigures
%\listoftables
\chapter*{Zusammenfassung}
\enlargethispage{10mm}
\selectlanguage{german}
Automatische Segmentierung und Erkennung von semantischen Klassen in
nat\"urlichen Bildern ist ein wichtiges offenes Problem des maschinellen Sehens.
In dieser Arbeit untersuchen wir drei m\"oglichen Ans\"atzen der Erkennung:
ohne \"Uberwachung, mit \"Uberwachung auf Ebene von Bildern und mit \"Uberwachung auf Ebene
von Pixeln. Diese Arbeit setzt sich aus drei Teilen zusammen.

Im ersten Teil der Arbeit schlagen wir einen Clustering-Algorithmus vor,
der eine neuartige, informationstheoretische Zielfunktion optimiert. Wir zeigen, dass
der vorgestellte Algorithmus \"ublichen Standardverfahren aus der Literatur gegen\"uber
klare Vorteile auf vielen verschiedenen Datens\"atzen hat. Clustering ist ein wichtiger
Baustein in vielen Applikationen des machinellen Sehens, insbesondere in der
automatischen Segmentierung.

Der zweite Teil dieser Arbeit stellt ein Verfahren zur automatischen
Segmentierung und Erkennung von Objektklassen in nat\"urlichen Bildern vor, der
mit Hilfe von Supervision in Form von Klassen-Vorkommen auf Bildern in der Lage
ist ein Segmentierungsmodell zu Lernen. Nach unserem Wissen ist dies der erste
Ansatz dieser Art, der sich speziell auf komplexe Objektklassen bezieht.

Der dritte und letzte Teil der Arbeit untersucht einen der am weitesten
verbreiteten Ans\"atze zu semantischen Segmentierung und
Objektklassensegmentierung, Conditional Random Fields, verbunden mit Verfahren
der strukturierten Vorhersage.
%Die Vorhersage f\"ur Modelle zur Bild-Markierung
%mittels Conditional Random Fields ist f\"ur gew\"ohnlich nur approiximativ
%moeglich, bedingt d\"urch das Vorhandensein von Kreisen in den zugrunde
%liegenden Nachbarschaftsgraphen.  Aus diesem Grund, und trotz der Beliebtheit
%von Conditional Random Field Verfahren, ist das strukturierte Lernen f\"ur
%solche Anwendungen schlecht verstanden.
%
Wir untersuchen verschiedene Lernalgorithmen des struktuierten Lernens, insbesondere
im Zusammenhang mit approximativer Inferenz. Wir zeigen, dass es m\"oglich ist trotz des Vorhandenseins von
Kreisen in den Nachbarschaftsgraphen exakte strukturierte Modelle zur Bildsegmentierung zu lernen.
Mit den vorgestellten Methoden bringen den Stand der Kunst
auf zwei komplexen Datens\"atzen zur semantischen Segmentierung voran, dem MSRC-21 Datensatz
von RGB-Bildern und dem NYU V2 Datensatz von RGB-D Bildern von Innenraum-Szenen.

Wir stellen au{\ss}erdem eine Software-Bibliothek vor, die es erlaubt einen
weitreichenden Vergleich der besten Lernverfahren f\"ur strukturiertes Lernen
durchzuf\"uhren.
Unsere Studie erlaubt uns eine Charakterisierung der betrachteten Algorithmen
in einer Reihe von Anwendungen, insbesondere der semantischen Segmentierung und
Objektklassensegmentierung.

\selectlanguage{english}
\chapter*{Abstract}
Automatic segmentation and recognition of semantic classes in natural images is
an important open problem in computer vision.
In this work, we investigates three different approaches to recognition: without supervision,
with supervision on level of images, and with supervision on the level of pixels.
The thesis comprises three parts.

The first part introduces a clustering algorithm that optimizes a novel
information-theoretic objective function. We show that the proposed algorithm
has clear advantages over standard algorithm from the literature on a wide
array of datasets. Clustering algorithms are an important building block for
higher level computer vision applications, in particular for semantic
segmentation.

The second part of this work proposes an algorithm for automatic segmentation
and recognition of object classes in natural images, that learns a segmentation
model solely from annotation in form of presence and absence of object classes
in images. To the best of our knowledge, this is the first algorithm that is
also able to addresses complex object classes.

The third and main part of this work investigates one of the most popular
approaches to the task of object class segmentation and semantic segmentation,
based on conditional random fields and structured prediction.

We investigate several learning algorithms, in particular in combination with
approximate inference procedures. We show how structured models for image
segmentation can be learned exactly in practical settings, even in the presence
of many loops in the underlying neighborhood graphs.
The introduced methods provide results advancing the state-of-the art on two
complex benchmark datasets for semantic segmention, the MSRC-21 Dataset of RGB
images and the NYU V2 Dataset or RGB-D images of indoor scenes.

Finally, we introduce a software library that allows us to perform extensive empirical
comparisons of state-of-the-art structured learning approaches. This allows us
to characterize their practical properties in a range of applications, in
particular for semantic segmentation and object class segmentation.


\chapter*{Acknowledgements}
First, I would like to thank my advisor Sven Behnke, who allowed me
to pursue my PhD in his department and who provided funding for my studies.
I would also like to thank J\"urgen Gall for agreeing to be my second reader.

During my work on this dissertation, my ideas were shaped by many of my fellow
students and researchers. First and foremost I am in debt to Hannes Schulz,
whose feedback proved to be invaluable during my studies.
I would like to thank Christoph Lampert for hosting me as a visiting researcher
at the IST Austria. His guidance and advice helped me in directing my further
research. My thanks are also extended to Sebastian Nowozin for his collaboration,
many helpful discussions, and advice.

I would also like to thank Carsten Rother for allowing me to work with him
at Microsoft Research Cambridge and hosting me there.

I have been lucky to be a part of the scikit-learn community, whose developers
have been a constant source of encouragement and inspiration to me. My
understanding of machine learning as well as software engineering has been
greatly affected by the continuing exchange with Olivier Grisel, Lars Buitinck,
Ga\"el Varoquax, Vlad Niculae, Mathieu Blondel, Gilles Louppe, Arnaud Joly and
others.

I also thank my parents and my sister for their support.

Last but not least I am grateful to Anna M\"uller for her support,
encouragement and company. Thank you for giving me the strength needed for this
endeavour.
\cleardoublepage
\pagenumbering{arabic}
\include{intro}

%\include{datasets/paper}

\include{itm/paper}

\include{partial_supervision/paper}

\include{structured_prediction/paper}
\include{pystruct/paper}

\include{evaluation/paper}

\include{exact_learning/paper}

\include{nyu/paper}

\chapter{Conclusion and Future Direction}
Current research in computer vision progresses at an incredible speed, with new
methods and applications emerging constantly.  Still, there are large
differences in the paradigms employed by different researchers.  While it is
generally acknowledged that context is one of the most important cues in
recognizing objects and interpreting scenes, there is little consensus on how
contextual information should be modelled, or even learned.
The structured prediction paradigm allows a principled approach to
incorporating predictions within an image, and to include context information.
We investigated the potential of structural methods for the application of
semantic image segmentation and object recognition, applications to which
structured methods have been applied successfully before.  We focus on
\emph{learning} of structural models and the interaction of inference and
learning in the neighborhood models typically employed for semantic
segmentation.
The thesis presents a software implementation of a variety of popular learning
algorithms for structural support vector machines, together with a thorough
evaluation of their properties in the presence of approximate inference.
We demonstrate that exact learning is possible, even in the presence of loops in the
underlying factor graph. We also demonstrate the power of conditioning interactions
on data, learning spacial interactions in a RGB-D setting.
%TODO STATE OF THE F*ING ART!

There are several directions for future research that we think would be
interesting to pursue as an extension of the presented results, in particular in
extending the second and third part:
\paragraph{Large-Scale Weakly Supervised Object Class Segmentation}
google
\paragraph{Inference Machines}
Recently \citet{stoyanov2011empirical} started a new trend in structured
prediction, which is sometimes called ``inference machines''. The basic
principle is simple: view the process of prediction with a given inference
procedure as a prediction method and optimize parameters of this method using
empirical risk minimization.  The work of \citet{stoyanov2011empirical}, used
loopy belief propagation as their inference algorithm and the optimization is
carried out simply using gradient descent on the non-convex but differentiable
loss function.  Other recent work in this direction includes
\citet{krahenbuhlparameter}, who used mean-field inference in a fully connected
conditional random field and \citet{jancsarylearning}, who used closed form
inference in a Gaussian CRF\@.
While these algorithms show great promise, their relation to the traditional
approach of structured prediction used in this work is mostly unclear. In particular,
if exact traditional learning is possible in a model, it is unclear how much
can be gained by direct empirical risk minimization.
Little empirical comparison was performed, and we are not aware of theoretical
work in this direction, leaving much room for future investigation of this
direction.
\paragraph{Non-Linear Models}
In this work, we only considered models that are linear in the input features--though
features are highly non-linear in the original input pixels.
Kernelization of structural support vector machines is trivial in theory, but
had only limited success in the context of CRFs for image
segmentation~\citep{lucchi2012structured}.
Two major alternatives for non-linear CRFs were proposed in the literature,
conditional neural fields~\citep{peng2009conditional} based on neural networks,
and decision tree fields~\citep{nowozin2011decision}, based on decision trees.
Conditional neural fields have only applied to sequence classification so far,
and extending them to our setting of semantic image segmentation would be very
interesting. Decision tree fields~(DTFs) on the other hand have been applied to loopy
graphs for image processing, but not for higher level tasks such as semantic
segmentation. If it is possible to include context in a meaningful way, it
might be possible to solve even object-centric tasks such as object class
segmentation with DTFs.

\paragraph{Latent Variable Models}
Something latent
\paragraph{Feature Design}
features are important
which low-level cues?
superpixels?

\bibliographystyle{plainnat}
\bibliography{main}
\end{document}
